# Otimiza√ß√£o Baseada no CoAtNet (93% Acur√°cia)

## üìä An√°lise do Paper CoAtNet

O paper "Parasitic egg recognition using convolution and attention network" demonstrou que o CoAtNet atingiu **93% de acur√°cia** no dataset Chula-ParasiteEgg-11. Analisamos as t√©cnicas utilizadas e implementamos otimiza√ß√µes para modelos leves.

## üîç T√©cnicas-Chave Identificadas

### 1. **Input Size Otimizado**
- **CoAtNet**: 384x384 pixels
- **Nossa implementa√ß√£o**: 384x384 (aumentado de 224x224)
- **Justificativa**: Maior resolu√ß√£o melhora a detec√ß√£o de detalhes microsc√≥picos

### 2. **Batch Size Otimizado**
- **CoAtNet**: 8-16 por GPU
- **Nossa implementa√ß√£o**: 8 (otimizado para RTX 2070 Super)
- **Justificativa**: Balanceia mem√≥ria e estabilidade do gradiente

### 3. **Learning Rate com Scheduler**
- **CoAtNet**: ReduceLROnPlateau
- **Nossa implementa√ß√£o**: ReduceLROnPlateau com factor=0.1, patience=5
- **Justificativa**: Reduz LR automaticamente quando performance para de melhorar

### 4. **Data Augmentation Espec√≠fico**
- **CoAtNet**: Blur e noise para simular condi√ß√µes microsc√≥picas
- **Nossa implementa√ß√£o**: 
  - GaussianBlur, MotionBlur, MedianBlur
  - GaussNoise, ISONoise, MultiplicativeNoise
  - Rota√ß√£o moderada (-15¬∞ a +15¬∞)
  - Ajustes de cor suaves

### 5. **Regulariza√ß√£o Moderada**
- **CoAtNet**: Dropout 0.5
- **Nossa implementa√ß√£o**: 
  - Dropout 0.5
  - Weight decay 5e-4 (reduzido)
  - Label smoothing 0.1
  - Gradient clipping 1.0

### 6. **Fine-tuning Completo**
- **CoAtNet**: Todas as camadas treinadas
- **Nossa implementa√ß√£o**: Fine-tuning completo dos modelos leves

## üöÄ Configura√ß√µes Implementadas

### `config_optimized.py`
```python
# Configura√ß√µes baseadas no CoAtNet
image_size: int = 384          # Aumentado de 224
batch_size: int = 8            # Otimizado para RTX 2070 Super
learning_rate: float = 1e-4    # Learning rate moderado
weight_decay: float = 5e-4     # Regulariza√ß√£o moderada
num_epochs: int = 50           # Mais √©pocas para converg√™ncia

# Learning rate scheduler
scheduler_factor: float = 0.1
scheduler_patience: int = 5
scheduler_min_lr: float = 1e-6

# Augmentation espec√≠fico
augmentation_blur: bool = True
augmentation_noise: bool = True
augmentation_rotation: int = 15
```

### `dataset_optimized.py`
- **Augmentation baseado no CoAtNet**:
  - Blur: GaussianBlur, MotionBlur, MedianBlur
  - Noise: GaussNoise, ISONoise, MultiplicativeNoise
  - Transforma√ß√µes geom√©tricas moderadas
  - Ajustes de cor suaves

### `trainer_optimized.py`
- **Learning rate scheduler**: ReduceLROnPlateau
- **Gradient clipping**: 1.0
- **Label smoothing**: 0.1
- **Early stopping**: Mais paciente (patience=15)

## üìà Compara√ß√£o de Configura√ß√µes

| Aspecto | Light | Improved | Optimized (CoAtNet) |
|---------|-------|----------|---------------------|
| Image Size | 224x224 | 224x224 | **384x384** |
| Batch Size | 32 | 16 | **8** |
| Learning Rate | 1e-3 | 5e-5 | **1e-4** |
| Weight Decay | 1e-4 | 1e-3 | **5e-4** |
| Dropout | 0.3 | 0.5 | **0.5** |
| LR Scheduler | ‚ùå | ‚ùå | **‚úÖ ReduceLROnPlateau** |
| Augmentation | B√°sico | Agressivo | **Blur + Noise** |
| Gradient Clipping | ‚ùå | ‚úÖ | **‚úÖ** |
| Label Smoothing | ‚ùå | ‚úÖ | **‚úÖ** |

## üéØ Expectativas de Melhoria

### Baseado no CoAtNet (93% acur√°cia):
1. **Input size maior**: +5-10% acur√°cia
2. **Augmentation espec√≠fico**: +3-5% acur√°cia
3. **LR scheduler**: +2-3% acur√°cia
4. **Regulariza√ß√£o otimizada**: Melhor generaliza√ß√£o

### Meta Realista:
- **Acur√°cia de teste**: 75-80% (vs 68-74% atual)
- **Redu√ß√£o do overfitting**: Gap valida√ß√£o-teste < 10%
- **Melhor F1-score**: Especialmente para classes dif√≠ceis

## üîß Como Executar

### Treinar todos os modelos:
```bash
cd parasyte-detector
source parasite_env/bin/activate
python run_optimized.py --model all
```

### Treinar modelo espec√≠fico:
```bash
python run_optimized.py --model hybrid
```

### Arquivos gerados:
- `results_optimized/`: Resultados e gr√°ficos
- `models_optimized/`: Modelos treinados
- `logs_optimized/`: Logs de treinamento

## üìä Monitoramento

### M√©tricas importantes:
1. **Acur√°cia de teste**: Meta > 75%
2. **Gap valida√ß√£o-teste**: Meta < 10%
3. **F1-score por classe**: Especialmente classes dif√≠ceis
4. **Tempo de treinamento**: ~2-3 horas por modelo

### Gr√°ficos gerados:
- Hist√≥rico de treinamento
- Matriz de confus√£o
- Compara√ß√£o de modelos
- An√°lise de overfitting

## üéØ Pr√≥ximos Passos

1. **Executar experimento otimizado**
2. **Comparar com resultados anteriores**
3. **Analisar m√©tricas por classe**
4. **Ajustar hiperpar√¢metros se necess√°rio**
5. **Testar ensemble dos melhores modelos**

## üìö Refer√™ncias

- **Paper CoAtNet**: "Parasitic egg recognition using convolution and attention network"
- **Dataset**: Chula-ParasiteEgg-11 (ICIP 2022 Challenge)
- **T√©cnicas**: ReduceLROnPlateau, Blur+Noise augmentation, Gradient clipping 