# ClassificaÃ§Ã£o de Ovos de Parasitas - Estudo Comparativo de Modelos

Este projeto implementa e compara trÃªs modelos de deep learning state-of-the-art para classificaÃ§Ã£o de ovos de parasitas utilizando o dataset Chula-ParasiteEgg-11. O estudo foi projetado para uma tese de bacharelado comparando arquiteturas CNN, Vision Transformer e HÃ­brida.

## ğŸ¯ VisÃ£o Geral do Projeto

O objetivo Ã© classificar 11 tipos diferentes de ovos de parasitas a partir de imagens mÃ©dicas:
- Ascaris lumbricoides
- Capillaria philippinensis  
- Enterobius vermicularis
- Fasciolopsis buski
- Ovo de AncilÃ³stomo
- Hymenolepis diminuta
- Hymenolepis nana
- Opisthorchis viverrine
- Paragonimus spp
- Ovo de Taenia spp.
- Trichuris trichiura

## ğŸ—ï¸ Arquiteturas dos Modelos

### 1. Modelo CNN - EfficientNetV2-S
- **Arquitetura**: EfficientNetV2-S com classificador customizado
- **Vantagens**: 
  - Performance comprovada em tarefas de imagens mÃ©dicas
  - Uso eficiente de parÃ¢metros
  - Excelentes capacidades de transfer learning
- **Caso de Uso**: Performance baseline CNN para comparaÃ§Ã£o

### 2. Vision Transformer - Tiny ViT
- **Arquitetura**: Vision Transformer Tiny com design compacto
- **Vantagens**:
  - Performance state-of-the-art em anÃ¡lise de imagens mÃ©dicas
  - Captura caracterÃ­sticas locais e globais
  - Mecanismo de atenÃ§Ã£o eficiente
- **Caso de Uso**: Abordagem moderna baseada em transformer

### 3. Modelo HÃ­brido - EfficientNetV2-S + Tiny ViT
- **Arquitetura**: Combina backbone CNN EfficientNetV2-S com Vision Transformer Tiny
- **Vantagens**:
  - Melhor dos dois mundos: extraÃ§Ã£o de caracterÃ­sticas locais da CNN + atenÃ§Ã£o global do ViT
  - FusÃ£o de caracterÃ­sticas baseada em atenÃ§Ã£o
  - Performance superior atravÃ©s de forÃ§as complementares
- **Caso de Uso**: Abordagem hÃ­brida avanÃ§ada para mÃ¡xima performance

## ğŸ“ Estrutura do Projeto

```
parasyte-detector/
â”œâ”€â”€ config.py                # ConfiguraÃ§Ãµes do modelo lightweight
â”œâ”€â”€ dataset.py               # Carregamento e prÃ©-processamento do dataset
â”œâ”€â”€ models.py                # Arquiteturas dos modelos
â”œâ”€â”€ trainer.py               # LÃ³gica de treinamento e avaliaÃ§Ã£o
â”œâ”€â”€ main.py                  # Script principal de execuÃ§Ã£o
â”œâ”€â”€ requirements.txt         # DependÃªncias Python
â”œâ”€â”€ README.md               # Este arquivo
â”œâ”€â”€ MODEL_ANALYSIS_LIGHT.md # AnÃ¡lise tÃ©cnica dos modelos lightweight
â”œâ”€â”€ Chula-ParasiteEgg-11/   # Dataset de treinamento
â”œâ”€â”€ Chula-ParasiteEgg-11_test/ # Dataset de teste
â”œâ”€â”€ models_light/           # Checkpoints dos modelos salvos
â”œâ”€â”€ results_light/          # Resultados de avaliaÃ§Ã£o e grÃ¡ficos
â””â”€â”€ logs_light/            # Logs do TensorBoard
```

## ğŸš€ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio**:
```bash
git clone <url-do-repositorio>
cd parasyte-detector
```

2. **Instale as dependÃªncias**:
```bash
pip install -r requirements.txt
```

3. **Verifique a estrutura do dataset**:
Certifique-se de que seu dataset estÃ¡ organizado como:
```
Chula-ParasiteEgg-11/
â””â”€â”€ data/
    â”œâ”€â”€ Ascaris lumbricoides/
    â”œâ”€â”€ Capillaria philippinensis/
    â”œâ”€â”€ Enterobius vermicularis/
    â””â”€â”€ ... (outras classes)
```

## ğŸ® Uso

### InÃ­cio RÃ¡pido
Execute o experimento completo comparando todos os trÃªs modelos:

```bash
python main.py
```

### Experimento Melhorado (Anti-Overfitting)
Execute o experimento com tÃ©cnicas anti-overfitting:

```bash
python run_improved.py
```

**Melhorias implementadas**:
- Data augmentation mais agressivo
- Dropout aumentado (0.2 â†’ 0.5)
- Learning rate reduzido (2e-4 â†’ 5e-5)
- Weight decay aumentado (1e-4 â†’ 1e-3)
- Label smoothing (0.1)
- Gradient clipping (1.0)
- Early stopping mais paciente (5 â†’ 10 Ã©pocas)

Isso irÃ¡:
- Treinar todos os trÃªs modelos (CNN, ViT, HÃ­brido)
- Gerar grÃ¡ficos de comparaÃ§Ã£o e mÃ©tricas
- Salvar resultados para anÃ¡lise da tese
- Criar relatÃ³rios abrangentes

### Treinamento Individual de Modelos
Treine um modelo especÃ­fico:

```python
from trainer import ParasiteTrainer
import config

# Treinar modelo CNN
trainer = ParasiteTrainer('cnn', config.config)
trainer.train()
trainer.evaluate()

# Treinar Vision Transformer
trainer = ParasiteTrainer('vit', config.config)
trainer.train()
trainer.evaluate()

# Treinar modelo HÃ­brido
trainer = ParasiteTrainer('hybrid', config.config)
trainer.train()
trainer.evaluate()
```

### ConfiguraÃ§Ã£o
Modifique `config.py` para ajustar hiperparÃ¢metros:

```python
# Exemplo de mudanÃ§as de configuraÃ§Ã£o
config.num_epochs = 100
config.batch_size = 16
config.learning_rate = 5e-5
config.image_size = 384
```

## ğŸ“Š Resultados e AnÃ¡lise

O experimento gera resultados abrangentes incluindo:

### MÃ©tricas de Performance
- **AcurÃ¡cia**: AcurÃ¡cia geral de classificaÃ§Ã£o
- **PrecisÃ£o/RevocaÃ§Ã£o/F1-Score**: Performance por classe
- **Matriz de ConfusÃ£o**: AnÃ¡lise detalhada de erros
- **Curvas de Treinamento**: Perda e acurÃ¡cia ao longo do tempo

### VisualizaÃ§Ãµes
- GrÃ¡ficos de comparaÃ§Ã£o de modelos
- HistÃ³rico de treinamento
- Matrizes de confusÃ£o
- Breakdown de performance por classe

### Arquivos de SaÃ­da
- `results_light/comparacao_modelos.json`: Dados detalhados de comparaÃ§Ã£o
- `results_light/relatorio_tese.json`: RelatÃ³rio abrangente da tese
- `results_light/*_historico_treinamento.png`: Curvas de treinamento
- `results_light/*_matriz_confusao.png`: Matrizes de confusÃ£o
- `models_light/melhor_*.pth`: Melhores checkpoints dos modelos

## ğŸ”¬ Design Experimental

### DivisÃ£o do Dataset
- **Treinamento**: 80% dos dados de treinamento (modelo aprende com esses dados)
- **ValidaÃ§Ã£o**: 20% dos dados de treinamento (monitoramento durante treinamento)
- **Teste**: Dataset de teste separado (avaliaÃ§Ã£o final real)

**âš ï¸ IMPORTANTE**: Os valores de validaÃ§Ã£o (95-98%) sÃ£o diferentes dos valores de teste (56-73%) porque:
- **ValidaÃ§Ã£o**: Vem do mesmo dataset de treinamento (dados similares)
- **Teste**: Dataset completamente separado (dados novos)
- **DiferenÃ§a**: Indica overfitting - o modelo memoriza os dados de treinamento

### Aumento de Dados
- Flips horizontais/verticais
- RotaÃ§Ãµes aleatÃ³rias
- Ajustes de brilho/contraste
- Efeitos de ruÃ­do e blur
- Jittering de cor

### EstratÃ©gia de Treinamento
- **Otimizador**: AdamW com weight decay
- **Scheduler**: ReduceLROnPlateau
- **Loss**: Cross-entropy loss
- **Early Stopping**: Baseado na acurÃ¡cia de validaÃ§Ã£o
- **Transfer Learning**: Modelos prÃ©-treinados no ImageNet

## ğŸ¯ Modelos Lightweight

Este projeto utiliza versÃµes lightweight dos modelos para treinamento eficiente em GPUs locais:

### EfficientNetV2-S (CNN)
- **ParÃ¢metros**: ~22M
- **Tamanho de entrada**: 224x224x3
- **Ideal para**: GPUs com 8GB VRAM ou menos

### Tiny ViT (Vision Transformer)
- **ParÃ¢metros**: ~5M
- **Tamanho de entrada**: 224x224x3
- **Patch size**: 16x16
- **DimensÃ£o de embedding**: 192

### Modelo HÃ­brido (EfficientNetV2-S + Tiny ViT)
- **Backbone CNN**: EfficientNetV2-S (~22M parÃ¢metros)
- **Backbone ViT**: Tiny ViT (~5M parÃ¢metros)
- **FusÃ£o**: Mecanismo de atenÃ§Ã£o para combinar caracterÃ­sticas

## ğŸ“ˆ Performance Esperada
- **AcurÃ¡cia**: 85â€“92% (ligeiramente menor que modelos grandes, mas muito mais rÃ¡pido)
- **Tempo de Treinamento**: 3â€“5x mais rÃ¡pido que modelos grandes
- **Melhor para**: Prototipagem, experimentos locais e iteraÃ§Ã£o rÃ¡pida
